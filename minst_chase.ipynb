{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "! pip freeze | grep fastbook || pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book() # Only needed in colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(path/'train/3').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threes = [Image.open(x) for x in (path/'train/3').ls()]\n",
    "sevens = [Image.open(x) for x in (path/'train/7').ls()]\n",
    "threes_v = [Image.open(x) for x in (path/'valid/3').ls()]\n",
    "sevens_v = [Image.open(x) for x in (path/'valid/7').ls()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sevens_v[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = torch.stack([tensor(x) for x in threes])\n",
    "t7 = torch.stack([tensor(x) for x in sevens])\n",
    "y3 = tensor([0] * len(threes))\n",
    "y7 = tensor([1] * len(sevens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3_v = torch.stack([tensor(x) for x in threes_v])\n",
    "t7_v = torch.stack([tensor(x) for x in sevens_v])\n",
    "y3_v = tensor([0] * len(threes_v))\n",
    "y7_v = tensor([1] * len(sevens_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.cat((y3, y7))\n",
    "y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.cat((t3, t7), 0).view(-1, 28 * 28).float() / 255\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tensor([0.00001] * (28 * 28)).requires_grad_()\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn((3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = tensor(.1).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = list(zip(images, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_v = torch.cat((t3_v, t7_v), 0).view(-1, 28 * 28).float() / 255\n",
    "data_set_v = list(zip(images_v, torch.cat((y3_v, y7_v))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(data_set, batch_size=256, shuffle=True)\n",
    "dl_v = DataLoader(data_set, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.0 / (1 + np.exp(-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()\n",
    "\n",
    "def validate(weights, bias, dl):\n",
    "  accuracy = tensor([])\n",
    "\n",
    "  for batch in dl:\n",
    "    [image_batch, y_batch] = batch\n",
    "    predictions = (image_batch @ weights + bias).sigmoid()    \n",
    "    accuracy = torch.cat((accuracy, torch.where(y_batch == 1, predictions >= 0.5, predictions < 0.5).float()), 0)\n",
    "  return round(accuracy.mean().item(), 4)\n",
    "\n",
    "def train_epoch(weights, bias, dl):\n",
    "  epochs = 20\n",
    "  accuracy = tensor([])\n",
    "  for i in range(epochs):\n",
    "    for batch in dl:\n",
    "      [image_batch, y_batch] = batch\n",
    "      predictions = (image_batch @ weights + bias).sigmoid()\n",
    "      # print('predictions', (image_batch @ weights + bias)[0:10])\n",
    "      # print(image_batch[0])\n",
    "      # print(image_batch @ weights + bias)\n",
    "      errors = torch.where(y_batch == 1, 1 - predictions, predictions)\n",
    "      \n",
    "      accuracy = torch.cat((accuracy, torch.where(y_batch == 1, predictions >= 0.5, predictions < 0.5).float()), 0)\n",
    "      # accuracy = torch.where(y_batch == 1, predictions >= 0.5, predictions < 0.5).float()\n",
    "\n",
    "      # print('accuracy current', accuracy.mean())\n",
    "      loss = errors.mean()\n",
    "      # print('loss', loss)\n",
    "      \n",
    "      loss.backward()\n",
    "      step = 1\n",
    "\n",
    "      # print('bias', bias.data, 'grad', bias.grad, 'weights', weights.data.mean(), 'grad', weights.grad.mean())\n",
    "      # print('weights', weights[0:10])\n",
    "      weights.data -=  weights.grad.data * step\n",
    "      # print('bias before', bias.data, bias.grad.data)\n",
    "      bias.data -= bias.grad.data * step\n",
    "      \n",
    "      \n",
    "      weights.grad = None\n",
    "      bias.grad = None\n",
    "\n",
    "    print(validate(weights, bias, dl_v), end = ' ')\n",
    "\n",
    "weights = init_params((28 * 28))\n",
    "bias = init_params(1)\n",
    "train_epoch(weights, bias, dl)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
